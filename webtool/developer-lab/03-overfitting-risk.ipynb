{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa85a7e1-3cf9-4d74-9743-763b26b86bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Developer Lab Notebook\n",
    "# Experiment: Measure Inference Cost and GPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95adf791-53e2-4f6d-bed9-75c5f5f1d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991920d6-d5c1-474f-b108-13b7b40bdbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4. The current result analysis does not fully address the risk of overfitting. Achieving 99.43% accuracy in CDS classification might be influenced \n",
    "by data imbalances or the characteristics of negative sampling (e.g., downsampling of non-CDS regions). It remains unclear whether the model relies \n",
    "on genuine sequence features or on confounding factors like ORF length. To improve confidence in the results, it would be helpful to include a \n",
    "confusion matrix, detailed performance on short ORFs (<300 bp), and further exploration of the modelâ€™s decision criteria. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576f3c9-80ee-45df-8378-331fe29f24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "from api.core import AnnotatorPipeline\n",
    "import orfipy_core as oc\n",
    "\n",
    "# Initialize\n",
    "annotator = AnnotatorPipeline()\n",
    "data_dir = Path('./data3')\n",
    "results = []\n",
    "\n",
    "# Helper: parse .gff\n",
    "def parse_gff(gff_file):\n",
    "    cds_coords = set()\n",
    "    with open(gff_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"#\"): continue\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            if len(parts) > 3 and parts[2] == \"CDS\":\n",
    "                cds_coords.add((int(parts[3]), int(parts[4]), parts[6]))\n",
    "    return cds_coords\n",
    "\n",
    "# Main experiment\n",
    "for fa_file in sorted(data_dir.glob(\"*.fa\")):\n",
    "    gff_file = fa_file.with_suffix(\".gff\")\n",
    "    if not gff_file.exists(): continue\n",
    "\n",
    "    print(f\"ðŸ“„ Processing {fa_file.name}\")\n",
    "    cds_truth = parse_gff(gff_file)\n",
    "\n",
    "    for record in SeqIO.parse(fa_file, \"fasta\"):\n",
    "        seq = str(record.seq)\n",
    "        seq_rc = str(record.seq.reverse_complement())\n",
    "        orfs_pos, orfs_neg = annotator._parse_orfs(\n",
    "            oc.start_search(seq, seq_rc, record.id, 10, 1000000, 'b',\n",
    "                            ['TTG', 'CTG', 'ATG', 'GTG'],\n",
    "                            ['TAA', 'TAG', 'TGA'], '1', True, False,\n",
    "                            False, False, True,\n",
    "                            [False, False, True, False, False])[2]\n",
    "        )\n",
    "\n",
    "        inputs = annotator._cds_input_parser(orfs_pos, \"+\") + annotator._cds_input_parser(orfs_neg, \"-\")\n",
    "        sequences = [x[\"sequence\"] for x in inputs]\n",
    "        meta = [{\"start\": x[\"start\"], \"end\": x[\"end\"], \"strand\": x[\"strand\"], \"len\": x[\"end\"] - x[\"start\"]} for x in inputs]\n",
    "        preds = annotator._prediction(annotator.model_cds, annotator.tokenizer, sequences)\n",
    "\n",
    "        for p, m in zip(preds, meta):\n",
    "            label = 1 if (m[\"start\"], m[\"end\"], m[\"strand\"]) in cds_truth else 0\n",
    "            results.append({\n",
    "                \"Genome\": fa_file.name,\n",
    "                \"Length\": m[\"len\"],\n",
    "                \"TrueLabel\": label,\n",
    "                \"PredLabel\": p\n",
    "            })\n",
    "\n",
    "# To CSV and visualization\n",
    "df = pd.DataFrame(results)\n",
    "bins = [0, 100, 200, 300, 400, 500, 1000, 2000, 10000]\n",
    "labels = [\"<100\", \"100-200\", \"200-300\", \"300-400\", \"400-500\", \"500-1000\", \"1000-2000\", \"â‰¥2000\"]\n",
    "df[\"LengthBin\"] = pd.cut(df[\"Length\"], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "summary = df.groupby(\"LengthBin\").apply(\n",
    "    lambda g: pd.Series({\n",
    "        \"Count\": len(g),\n",
    "        \"Precision\": np.mean((g[\"PredLabel\"] == 1) & (g[\"TrueLabel\"] == 1)) / max(np.mean(g[\"PredLabel\"] == 1), 1e-6),\n",
    "        \"Recall\": np.mean((g[\"PredLabel\"] == 1) & (g[\"TrueLabel\"] == 1)) / max(np.mean(g[\"TrueLabel\"] == 1), 1e-6),\n",
    "        \"Accuracy\": np.mean(g[\"PredLabel\"] == g[\"TrueLabel\"])\n",
    "    })\n",
    ").reset_index()\n",
    "\n",
    "summary.to_csv(\"cds_performance_by_orf_length.csv\", index=False)\n",
    "\n",
    "# Plot\n",
    "summary.plot(x=\"LengthBin\", y=[\"Precision\", \"Recall\", \"Accuracy\"], kind=\"bar\", figsize=(10, 6))\n",
    "plt.title(\"CDS Classifier Performance by ORF Length\")\n",
    "plt.ylabel(\"Metric Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GeneLM",
   "language": "python",
   "name": "genelm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
